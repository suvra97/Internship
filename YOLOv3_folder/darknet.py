{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"darknet.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1QnnB-l3c3AEgC7ZWN_e9mKwb8lEmVvpl","authorship_tag":"ABX9TyOToh0sUqmLgmfMv86Edy33"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"uQVflnADNTGT","colab_type":"code","outputId":"2b21ed85-f13a-4b86-b63e-b2a93abcc438","executionInfo":{"status":"ok","timestamp":1588865991862,"user_tz":-330,"elapsed":31504,"user":{"displayName":"Suvramalya Basak","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiruymcmZiCy93QbAK7JUCD4nm8TZqpGuiaizyv=s64","userId":"10962232911980987514"}},"colab":{"base_uri":"https://localhost:8080/","height":129}},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mnpEAg21Negc","colab_type":"code","outputId":"9d57de12-1fe6-4468-a089-a656701da4fa","executionInfo":{"status":"ok","timestamp":1588869005044,"user_tz":-330,"elapsed":4481,"user":{"displayName":"Suvramalya Basak","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiruymcmZiCy93QbAK7JUCD4nm8TZqpGuiaizyv=s64","userId":"10962232911980987514"}},"colab":{"base_uri":"https://localhost:8080/","height":293}},"source":["%ls \"/content/drive/My Drive\""],"execution_count":1,"outputs":[{"output_type":"stream","text":[" 100010596.jpg\n"," abstract.docx\n","\u001b[0m\u001b[01;34m'Colab Notebooks'\u001b[0m/\n"," \u001b[01;34mdata\u001b[0m/\n"," Guidelines_for_report_Preparation__MSc_IIIrd_sem\n","'Guidelines_for_report_Preparation__MSc_IIIrd_sem (1).gdoc'\n","'Guidelines_for_report_Preparation__MSc_IIIrd_sem (2).gdoc'\n","'Guidelines_for_report_Preparation__MSc_IIIrd_sem (3).gdoc'\n","'Guidelines_for_report_Preparation__MSc_IIIrd_sem (4).gdoc'\n"," Guidelines_for_report_Preparation__MSc_IIIrd_sem.gdoc\n","'MC0717_lab_manual (1).pdf'\n"," \u001b[01;34mProject\u001b[0m/\n","'Suvramalya Basak (1).pdf'\n","'Suvramalya Basak.pdf'\n","'~uTorrentPartFile_2F6A1BE0.dat'\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lJ7r9_3wMxaH","colab_type":"code","colab":{}},"source":["from __future__ import division"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DqhWOaf6OXsX","colab_type":"code","outputId":"20090a54-010f-4889-e610-97235c370c53","executionInfo":{"status":"ok","timestamp":1588879805554,"user_tz":-330,"elapsed":6904,"user":{"displayName":"Suvramalya Basak","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiruymcmZiCy93QbAK7JUCD4nm8TZqpGuiaizyv=s64","userId":"10962232911980987514"}},"colab":{"base_uri":"https://localhost:8080/","height":202}},"source":["pip install import_ipynb"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Collecting import_ipynb\n","  Downloading https://files.pythonhosted.org/packages/63/35/495e0021bfdcc924c7cdec4e9fbb87c88dd03b9b9b22419444dc370c8a45/import-ipynb-0.1.3.tar.gz\n","Building wheels for collected packages: import-ipynb\n","  Building wheel for import-ipynb (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for import-ipynb: filename=import_ipynb-0.1.3-cp36-none-any.whl size=2976 sha256=c858ab80c191176779fa365f15b2bc57ab41b5095b64cea067470647115ed4c4\n","  Stored in directory: /root/.cache/pip/wheels/b4/7b/e9/a3a6e496115dffdb4e3085d0ae39ffe8a814eacc44bbf494b5\n","Successfully built import-ipynb\n","Installing collected packages: import-ipynb\n","Successfully installed import-ipynb-0.1.3\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xhfpYESCShNU","colab_type":"code","colab":{}},"source":["pip install -U -q PyDrive\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"lfX3rsuoSrpU","colab_type":"code","colab":{}},"source":["from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","\n","# Authenticate and create the PyDrive client.\n","# This only needs to be done once per notebook.\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)\n","\n","# Copy the link and remove the front part of the link (i.e. https://drive.google.com/open?id=) to get the file ID.\n","your_module = drive.CreateFile({'id':'1KcZoP8-pTdJpiRxYR2j-U58dcRpYEjbJ'})\n","your_module.GetContentFile('util.ipynb')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ex1mxxJAPzeA","colab_type":"code","outputId":"02b7e17a-8c40-46e6-f5a7-d36cb27138ac","executionInfo":{"status":"ok","timestamp":1588840210221,"user_tz":-330,"elapsed":848,"user":{"displayName":"Suvramalya Basak","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiruymcmZiCy93QbAK7JUCD4nm8TZqpGuiaizyv=s64","userId":"10962232911980987514"}},"colab":{"base_uri":"https://localhost:8080/","height":219}},"source":["import sys\n","sys.path\n"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['',\n"," '/env/python',\n"," '/usr/lib/python36.zip',\n"," '/usr/lib/python3.6',\n"," '/usr/lib/python3.6/lib-dynload',\n"," '/usr/local/lib/python3.6/dist-packages',\n"," '/usr/lib/python3/dist-packages',\n"," '/usr/local/lib/python3.6/dist-packages/IPython/extensions',\n"," '/root/.ipython',\n"," '/content/gdrive/My Drive',\n"," '/content/gdrive/My Drive/Project']"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"code","metadata":{"id":"cj0Yo5G_QJ4S","colab_type":"code","colab":{}},"source":["sys.path.append('/content/gdrive/My Drive/Project')\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8yL95KNdM2KZ","colab_type":"code","outputId":"88c17ddc-d067-42ea-ff03-7066bd97d4ee","executionInfo":{"status":"ok","timestamp":1588879812328,"user_tz":-330,"elapsed":1647,"user":{"displayName":"Suvramalya Basak","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiruymcmZiCy93QbAK7JUCD4nm8TZqpGuiaizyv=s64","userId":"10962232911980987514"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.autograd import Variable\n","import numpy as np\n","import import_ipynb\n","from util import * "],"execution_count":4,"outputs":[{"output_type":"stream","text":["importing Jupyter notebook from util.ipynb\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"w9pYKKGXM4zK","colab_type":"code","colab":{}},"source":["class EmptyLayer(nn.Module):\n","    def __init__(self):\n","        super(EmptyLayer, self).__init__()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UmDIE_5KM6_g","colab_type":"code","colab":{}},"source":["class DetectionLayer(nn.Module):\n","    def __init__(self, anchors):\n","        super(DetectionLayer, self).__init__()\n","        self.anchors = anchors"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kR8pd-ssM9CL","colab_type":"code","colab":{}},"source":["def get_test_input():\n","    img = cv2.imread(\"/content/drive/My Drive/Project/SSDB00059.JPG\")\n","    img = cv2.resize(img, (608,608))          #Resize to the input dimension\n","    img_ =  img[:,:,::-1].transpose((2,0,1))  # BGR -> RGB | H X W C -> C X H X W \n","    img_ = img_[np.newaxis,:,:,:]/255.0       #Add a channel at 0 (for batch) | Normalise\n","    img_ = torch.from_numpy(img_).float()     #Convert to float\n","    img_ = Variable(img_)                     # Convert to Variable\n","    return img_"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XU95dLHYM-5q","colab_type":"code","colab":{}},"source":["def parse_cfg(cfgfile):\n","    \"\"\"\n","    Takes a configuration file\n","    \n","    Returns a list of blocks. Each blocks describes a block in the neural\n","    network to be built. Block is represented as a dictionary in the list\n","    \n","    \"\"\"\n","    \n","    file = open(cfgfile, 'r')\n","    lines = file.read().split('\\n')                        # store the lines in a list\n","    lines = [x for x in lines if len(x) > 0]               # get read of the empty lines \n","    lines = [x for x in lines if x[0] != '#']              # get rid of comments\n","    lines = [x.rstrip().lstrip() for x in lines]           # get rid of fringe whitespaces\n","    \n","    block = {}\n","    blocks = []\n","\n","    for line in lines:\n","        if line[0] == \"[\":               # This marks the start of a new block\n","            if len(block) != 0:          # If block is not empty, implies it is storing values of previous block.\n","                blocks.append(block)     # add it the blocks list\n","                block = {}               # re-init the block\n","            block[\"type\"] = line[1:-1].rstrip()     \n","        else:\n","            key,value = line.split(\"=\") \n","            block[key.rstrip()] = value.lstrip()\n","    blocks.append(block)\n","\n","    return blocks"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rbuVUl7pNC3i","colab_type":"code","colab":{}},"source":["def create_modules(blocks):\n","    net_info = blocks[0]     #Captures the information about the input and pre-processing    \n","    module_list = nn.ModuleList()\n","    prev_filters = 3\n","    output_filters = []\n","    for index, x in enumerate(blocks[1:]):\n","        module = nn.Sequential()\n","\n","        #check the type of block\n","        #create a new module for the block\n","        #append to module_list\n","        \n","        if (x[\"type\"] == \"convolutional\"):\n","            #Get the info about the layer\n","            activation = x[\"activation\"]\n","            try:\n","                batch_normalize = int(x[\"batch_normalize\"])\n","                bias = False\n","            except:\n","                batch_normalize = 0\n","                bias = True\n","\n","            filters= int(x[\"filters\"])\n","            padding = int(x[\"pad\"])\n","            kernel_size = int(x[\"size\"])\n","            stride = int(x[\"stride\"])\n","\n","            if padding:\n","                pad = (kernel_size - 1) // 2\n","            else:\n","                pad = 0\n","\n","            #Add the convolutional layer\n","            conv = nn.Conv2d(prev_filters, filters, kernel_size, stride, pad, bias = bias)\n","            module.add_module(\"conv_{0}\".format(index), conv)\n","\n","            #Add the Batch Norm Layer\n","            if batch_normalize:\n","                bn = nn.BatchNorm2d(filters)\n","                module.add_module(\"batch_norm_{0}\".format(index), bn)\n","\n","            #Check the activation. \n","            #It is either Linear or a Leaky ReLU for YOLO\n","            if activation == \"leaky\":\n","                activn = nn.LeakyReLU(0.1, inplace = True)\n","                module.add_module(\"leaky_{0}\".format(index), activn)\n","\n","            #If it's an upsampling layer\n","            #We use Bilinear2dUpsampling\n","        elif (x[\"type\"] == \"upsample\"):\n","            stride = int(x[\"stride\"])\n","            upsample = nn.Upsample(scale_factor = 2, mode = \"bilinear\")\n","            module.add_module(\"upsample_{}\".format(index), upsample)\n","            \n","             #If it is a route layer\n","        elif (x[\"type\"] == \"route\"):\n","            x[\"layers\"] = x[\"layers\"].split(',')\n","            #Start  of a route\n","            start = int(x[\"layers\"][0])\n","            #end, if there exists one.\n","            try:\n","                end = int(x[\"layers\"][1])\n","            except:\n","                end = 0\n","            #Positive anotation\n","            if start > 0: \n","                start = start - index\n","            if end > 0:\n","                end = end - index\n","            route = EmptyLayer()\n","            module.add_module(\"route_{0}\".format(index), route)\n","            if end < 0:\n","                filters = output_filters[index + start] + output_filters[index + end]\n","            else:\n","                filters= output_filters[index + start]\n","\n","        #shortcut corresponds to skip connection\n","        elif x[\"type\"] == \"shortcut\":\n","            shortcut = EmptyLayer()\n","            module.add_module(\"shortcut_{}\".format(index), shortcut)\n","        \n","        #Yolo is the detection layer\n","        elif x[\"type\"] == \"yolo\":\n","            mask = x[\"mask\"].split(\",\")\n","            mask = [int(x) for x in mask]\n","    \n","            anchors = x[\"anchors\"].split(\",\")\n","            anchors = [int(a) for a in anchors]\n","            anchors = [(anchors[i], anchors[i+1]) for i in range(0, len(anchors),2)]\n","            anchors = [anchors[i] for i in mask]\n","    \n","            detection = DetectionLayer(anchors)\n","            module.add_module(\"Detection_{}\".format(index), detection)\n","                              \n","        module_list.append(module)\n","        prev_filters = filters\n","        output_filters.append(filters)\n","        \n","    return (net_info, module_list)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YHzw5a8SNIAE","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"7172d12e-b97b-4e8c-83eb-765c014cdcbe","executionInfo":{"status":"ok","timestamp":1588879835548,"user_tz":-330,"elapsed":2112,"user":{"displayName":"Suvramalya Basak","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiruymcmZiCy93QbAK7JUCD4nm8TZqpGuiaizyv=s64","userId":"10962232911980987514"}}},"source":["blocks = parse_cfg(\"/content/drive/My Drive/Project/yolov3.cfg\")\n","print(create_modules(blocks))"],"execution_count":10,"outputs":[{"output_type":"stream","text":["({'type': 'net', 'batch': '64', 'subdivisions': '16', 'width': '608', 'height': '608', 'channels': '3', 'momentum': '0.9', 'decay': '0.0005', 'angle': '0', 'saturation': '1.5', 'exposure': '1.5', 'hue': '.1', 'learning_rate': '0.001', 'burn_in': '1000', 'max_batches': '500200', 'policy': 'steps', 'steps': '400000,450000', 'scales': '.1,.1'}, ModuleList(\n","  (0): Sequential(\n","    (conv_0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (batch_norm_0): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (leaky_0): LeakyReLU(negative_slope=0.1, inplace=True)\n","  )\n","  (1): Sequential(\n","    (conv_1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","    (batch_norm_1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (leaky_1): LeakyReLU(negative_slope=0.1, inplace=True)\n","  )\n","  (2): Sequential(\n","    (conv_2): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (batch_norm_2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (leaky_2): LeakyReLU(negative_slope=0.1, inplace=True)\n","  )\n","  (3): Sequential(\n","    (conv_3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (batch_norm_3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (leaky_3): LeakyReLU(negative_slope=0.1, inplace=True)\n","  )\n","  (4): Sequential(\n","    (shortcut_4): EmptyLayer()\n","  )\n","  (5): Sequential(\n","    (conv_5): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","    (batch_norm_5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (leaky_5): LeakyReLU(negative_slope=0.1, inplace=True)\n","  )\n","  (6): Sequential(\n","    (conv_6): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (batch_norm_6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (leaky_6): LeakyReLU(negative_slope=0.1, inplace=True)\n","  )\n","  (7): Sequential(\n","    (conv_7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (batch_norm_7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (leaky_7): LeakyReLU(negative_slope=0.1, inplace=True)\n","  )\n","  (8): Sequential(\n","    (shortcut_8): EmptyLayer()\n","  )\n","  (9): Sequential(\n","    (conv_9): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (batch_norm_9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (leaky_9): LeakyReLU(negative_slope=0.1, inplace=True)\n","  )\n","  (10): Sequential(\n","    (conv_10): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (batch_norm_10): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (leaky_10): LeakyReLU(negative_slope=0.1, inplace=True)\n","  )\n","  (11): Sequential(\n","    (shortcut_11): EmptyLayer()\n","  )\n","  (12): Sequential(\n","    (conv_12): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","    (batch_norm_12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (leaky_12): LeakyReLU(negative_slope=0.1, inplace=True)\n","  )\n","  (13): Sequential(\n","    (conv_13): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (batch_norm_13): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (leaky_13): LeakyReLU(negative_slope=0.1, inplace=True)\n","  )\n","  (14): Sequential(\n","    (conv_14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (batch_norm_14): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (leaky_14): LeakyReLU(negative_slope=0.1, inplace=True)\n","  )\n","  (15): Sequential(\n","    (shortcut_15): EmptyLayer()\n","  )\n","  (16): Sequential(\n","    (conv_16): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (batch_norm_16): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (leaky_16): LeakyReLU(negative_slope=0.1, inplace=True)\n","  )\n","  (17): Sequential(\n","    (conv_17): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (batch_norm_17): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (leaky_17): LeakyReLU(negative_slope=0.1, inplace=True)\n","  )\n","  (18): Sequential(\n","    (shortcut_18): EmptyLayer()\n","  )\n","  (19): Sequential(\n","    (conv_19): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (batch_norm_19): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (leaky_19): LeakyReLU(negative_slope=0.1, inplace=True)\n","  )\n","  (20): Sequential(\n","    (conv_20): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (batch_norm_20): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (leaky_20): LeakyReLU(negative_slope=0.1, inplace=True)\n","  )\n","  (21): Sequential(\n","    (shortcut_21): EmptyLayer()\n","  )\n","  (22): Sequential(\n","    (conv_22): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (batch_norm_22): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (leaky_22): LeakyReLU(negative_slope=0.1, inplace=True)\n","  )\n","  (23): Sequential(\n","    (conv_23): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (batch_norm_23): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (leaky_23): LeakyReLU(negative_slope=0.1, inplace=True)\n","  )\n","  (24): Sequential(\n","    (shortcut_24): EmptyLayer()\n","  )\n","  (25): Sequential(\n","    (conv_25): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (batch_norm_25): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (leaky_25): LeakyReLU(negative_slope=0.1, inplace=True)\n","  )\n","  (26): Sequential(\n","    (conv_26): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (batch_norm_26): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (leaky_26): LeakyReLU(negative_slope=0.1, inplace=True)\n","  )\n","  (27): Sequential(\n","    (shortcut_27): EmptyLayer()\n","  )\n","  (28): Sequential(\n","    (conv_28): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (batch_norm_28): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (leaky_28): LeakyReLU(negative_slope=0.1, inplace=True)\n","  )\n","  (29): Sequential(\n","    (conv_29): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (batch_norm_29): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (leaky_29): LeakyReLU(negative_slope=0.1, inplace=True)\n","  )\n","  (30): Sequential(\n","    (shortcut_30): EmptyLayer()\n","  )\n","  (31): Sequential(\n","    (conv_31): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (batch_norm_31): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (leaky_31): LeakyReLU(negative_slope=0.1, inplace=True)\n","  )\n","  (32): Sequential(\n","    (conv_32): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (batch_norm_32): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (leaky_32): LeakyReLU(negative_slope=0.1, inplace=True)\n","  )\n","  (33): Sequential(\n","    (shortcut_33): EmptyLayer()\n","  )\n","  (34): Sequential(\n","    (conv_34): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (batch_norm_34): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (leaky_34): LeakyReLU(negative_slope=0.1, inplace=True)\n","  )\n","  (35): Sequential(\n","    (conv_35): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (batch_norm_35): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (leaky_35): LeakyReLU(negative_slope=0.1, inplace=True)\n","  )\n","  (36): Sequential(\n","    (shortcut_36): EmptyLayer()\n","  )\n","  (37): Sequential(\n","    (conv_37): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","    (batch_norm_37): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (leaky_37): LeakyReLU(negative_slope=0.1, inplace=True)\n","  )\n","  (38): Sequential(\n","    (conv_38): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (batch_norm_38): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (leaky_38): LeakyReLU(negative_slope=0.1, inplace=True)\n","  )\n","  (39): Sequential(\n","    (conv_39): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (batch_norm_39): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (leaky_39): LeakyReLU(negative_slope=0.1, inplace=True)\n","  )\n","  (40): Sequential(\n","    (shortcut_40): EmptyLayer()\n","  )\n","  (41): Sequential(\n","    (conv_41): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (batch_norm_41): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (leaky_41): LeakyReLU(negative_slope=0.1, inplace=True)\n","  )\n","  (42): Sequential(\n","    (conv_42): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (batch_norm_42): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (leaky_42): LeakyReLU(negative_slope=0.1, inplace=True)\n","  )\n","  (43): Sequential(\n","    (shortcut_43): EmptyLayer()\n","  )\n","  (44): Sequential(\n","    (conv_44): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (batch_norm_44): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (leaky_44): LeakyReLU(negative_slope=0.1, inplace=True)\n","  )\n","  (45): Sequential(\n","    (conv_45): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (batch_norm_45): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (leaky_45): LeakyReLU(negative_slope=0.1, inplace=True)\n","  )\n","  (46): Sequential(\n","    (shortcut_46): EmptyLayer()\n","  )\n","  (47): Sequential(\n","    (conv_47): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (batch_norm_47): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (leaky_47): LeakyReLU(negative_slope=0.1, inplace=True)\n","  )\n","  (48): Sequential(\n","    (conv_48): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (batch_norm_48): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (leaky_48): LeakyReLU(negative_slope=0.1, inplace=True)\n","  )\n","  (49): Sequential(\n","    (shortcut_49): EmptyLayer()\n","  )\n","  (50): Sequential(\n","    (conv_50): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (batch_norm_50): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (leaky_50): LeakyReLU(negative_slope=0.1, inplace=True)\n","  )\n","  (51): Sequential(\n","    (conv_51): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (batch_norm_51): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (leaky_51): LeakyReLU(negative_slope=0.1, inplace=True)\n","  )\n","  (52): Sequential(\n","    (shortcut_52): EmptyLayer()\n","  )\n","  (53): Sequential(\n","    (conv_53): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (batch_norm_53): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (leaky_53): LeakyReLU(negative_slope=0.1, inplace=True)\n","  )\n","  (54): Sequential(\n","    (conv_54): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (batch_norm_54): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (leaky_54): LeakyReLU(negative_slope=0.1, inplace=True)\n","  )\n","  (55): Sequential(\n","    (shortcut_55): EmptyLayer()\n","  )\n","  (56): Sequential(\n","    (conv_56): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (batch_norm_56): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (leaky_56): LeakyReLU(negative_slope=0.1, inplace=True)\n","  )\n","  (57): Sequential(\n","    (conv_57): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (batch_norm_57): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (leaky_57): LeakyReLU(negative_slope=0.1, inplace=True)\n","  )\n","  (58): Sequential(\n","    (shortcut_58): EmptyLayer()\n","  )\n","  (59): Sequential(\n","    (conv_59): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (batch_norm_59): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (leaky_59): LeakyReLU(negative_slope=0.1, inplace=True)\n","  )\n","  (60): Sequential(\n","    (conv_60): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (batch_norm_60): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (leaky_60): LeakyReLU(negative_slope=0.1, inplace=True)\n","  )\n","  (61): Sequential(\n","    (shortcut_61): EmptyLayer()\n","  )\n","  (62): Sequential(\n","    (conv_62): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","    (batch_norm_62): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (leaky_62): LeakyReLU(negative_slope=0.1, inplace=True)\n","  )\n","  (63): Sequential(\n","    (conv_63): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (batch_norm_63): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (leaky_63): LeakyReLU(negative_slope=0.1, inplace=True)\n","  )\n","  (64): Sequential(\n","    (conv_64): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (batch_norm_64): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (leaky_64): LeakyReLU(negative_slope=0.1, inplace=True)\n","  )\n","  (65): Sequential(\n","    (shortcut_65): EmptyLayer()\n","  )\n","  (66): Sequential(\n","    (conv_66): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (batch_norm_66): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (leaky_66): LeakyReLU(negative_slope=0.1, inplace=True)\n","  )\n","  (67): Sequential(\n","    (conv_67): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (batch_norm_67): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (leaky_67): LeakyReLU(negative_slope=0.1, inplace=True)\n","  )\n","  (68): Sequential(\n","    (shortcut_68): EmptyLayer()\n","  )\n","  (69): Sequential(\n","    (conv_69): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (batch_norm_69): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (leaky_69): LeakyReLU(negative_slope=0.1, inplace=True)\n","  )\n","  (70): Sequential(\n","    (conv_70): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (batch_norm_70): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (leaky_70): LeakyReLU(negative_slope=0.1, inplace=True)\n","  )\n","  (71): Sequential(\n","    (shortcut_71): EmptyLayer()\n","  )\n","  (72): Sequential(\n","    (conv_72): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (batch_norm_72): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (leaky_72): LeakyReLU(negative_slope=0.1, inplace=True)\n","  )\n","  (73): Sequential(\n","    (conv_73): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (batch_norm_73): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (leaky_73): LeakyReLU(negative_slope=0.1, inplace=True)\n","  )\n","  (74): Sequential(\n","    (shortcut_74): EmptyLayer()\n","  )\n","  (75): Sequential(\n","    (conv_75): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (batch_norm_75): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (leaky_75): LeakyReLU(negative_slope=0.1, inplace=True)\n","  )\n","  (76): Sequential(\n","    (conv_76): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (batch_norm_76): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (leaky_76): LeakyReLU(negative_slope=0.1, inplace=True)\n","  )\n","  (77): Sequential(\n","    (conv_77): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (batch_norm_77): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (leaky_77): LeakyReLU(negative_slope=0.1, inplace=True)\n","  )\n","  (78): Sequential(\n","    (conv_78): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (batch_norm_78): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (leaky_78): LeakyReLU(negative_slope=0.1, inplace=True)\n","  )\n","  (79): Sequential(\n","    (conv_79): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (batch_norm_79): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (leaky_79): LeakyReLU(negative_slope=0.1, inplace=True)\n","  )\n","  (80): Sequential(\n","    (conv_80): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (batch_norm_80): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (leaky_80): LeakyReLU(negative_slope=0.1, inplace=True)\n","  )\n","  (81): Sequential(\n","    (conv_81): Conv2d(1024, 255, kernel_size=(1, 1), stride=(1, 1))\n","  )\n","  (82): Sequential(\n","    (Detection_82): DetectionLayer()\n","  )\n","  (83): Sequential(\n","    (route_83): EmptyLayer()\n","  )\n","  (84): Sequential(\n","    (conv_84): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (batch_norm_84): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (leaky_84): LeakyReLU(negative_slope=0.1, inplace=True)\n","  )\n","  (85): Sequential(\n","    (upsample_85): Upsample(scale_factor=2.0, mode=bilinear)\n","  )\n","  (86): Sequential(\n","    (route_86): EmptyLayer()\n","  )\n","  (87): Sequential(\n","    (conv_87): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (batch_norm_87): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (leaky_87): LeakyReLU(negative_slope=0.1, inplace=True)\n","  )\n","  (88): Sequential(\n","    (conv_88): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (batch_norm_88): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (leaky_88): LeakyReLU(negative_slope=0.1, inplace=True)\n","  )\n","  (89): Sequential(\n","    (conv_89): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (batch_norm_89): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (leaky_89): LeakyReLU(negative_slope=0.1, inplace=True)\n","  )\n","  (90): Sequential(\n","    (conv_90): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (batch_norm_90): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (leaky_90): LeakyReLU(negative_slope=0.1, inplace=True)\n","  )\n","  (91): Sequential(\n","    (conv_91): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (batch_norm_91): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (leaky_91): LeakyReLU(negative_slope=0.1, inplace=True)\n","  )\n","  (92): Sequential(\n","    (conv_92): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (batch_norm_92): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (leaky_92): LeakyReLU(negative_slope=0.1, inplace=True)\n","  )\n","  (93): Sequential(\n","    (conv_93): Conv2d(512, 255, kernel_size=(1, 1), stride=(1, 1))\n","  )\n","  (94): Sequential(\n","    (Detection_94): DetectionLayer()\n","  )\n","  (95): Sequential(\n","    (route_95): EmptyLayer()\n","  )\n","  (96): Sequential(\n","    (conv_96): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (batch_norm_96): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (leaky_96): LeakyReLU(negative_slope=0.1, inplace=True)\n","  )\n","  (97): Sequential(\n","    (upsample_97): Upsample(scale_factor=2.0, mode=bilinear)\n","  )\n","  (98): Sequential(\n","    (route_98): EmptyLayer()\n","  )\n","  (99): Sequential(\n","    (conv_99): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (batch_norm_99): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (leaky_99): LeakyReLU(negative_slope=0.1, inplace=True)\n","  )\n","  (100): Sequential(\n","    (conv_100): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (batch_norm_100): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (leaky_100): LeakyReLU(negative_slope=0.1, inplace=True)\n","  )\n","  (101): Sequential(\n","    (conv_101): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (batch_norm_101): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (leaky_101): LeakyReLU(negative_slope=0.1, inplace=True)\n","  )\n","  (102): Sequential(\n","    (conv_102): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (batch_norm_102): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (leaky_102): LeakyReLU(negative_slope=0.1, inplace=True)\n","  )\n","  (103): Sequential(\n","    (conv_103): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (batch_norm_103): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (leaky_103): LeakyReLU(negative_slope=0.1, inplace=True)\n","  )\n","  (104): Sequential(\n","    (conv_104): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (batch_norm_104): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (leaky_104): LeakyReLU(negative_slope=0.1, inplace=True)\n","  )\n","  (105): Sequential(\n","    (conv_105): Conv2d(256, 255, kernel_size=(1, 1), stride=(1, 1))\n","  )\n","  (106): Sequential(\n","    (Detection_106): DetectionLayer()\n","  )\n","))\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"X5klae0ZTjjA","colab_type":"code","colab":{}},"source":["class Darknet(nn.Module):\n","    def __init__(self, cfgfile):\n","        super(Darknet, self).__init__()\n","        self.blocks = parse_cfg(cfgfile)\n","        self.net_info, self.module_list = create_modules(self.blocks)\n","        \n","    def forward(self, x, CUDA):\n","        modules = self.blocks[1:]\n","        outputs = {}   #We cache the outputs for the route layer\n","        \n","        write = 0\n","        for i, module in enumerate(modules):        \n","            module_type = (module[\"type\"])\n","            \n","            if module_type == \"convolutional\" or module_type == \"upsample\":\n","                x = self.module_list[i](x)\n","    \n","            elif module_type == \"route\":\n","                layers = module[\"layers\"]\n","                layers = [int(a) for a in layers]\n","    \n","                if (layers[0]) > 0:\n","                    layers[0] = layers[0] - i\n","    \n","                if len(layers) == 1:\n","                    x = outputs[i + (layers[0])]\n","    \n","                else:\n","                    if (layers[1]) > 0:\n","                        layers[1] = layers[1] - i\n","    \n","                    map1 = outputs[i + layers[0]]\n","                    map2 = outputs[i + layers[1]]\n","                    x = torch.cat((map1, map2), 1)\n","                \n","    \n","            elif  module_type == \"shortcut\":\n","                from_ = int(module[\"from\"])\n","                x = outputs[i-1] + outputs[i+from_]\n","    \n","            elif module_type == 'yolo':        \n","                anchors = self.module_list[i][0].anchors\n","                #Get the input dimensions\n","                inp_dim = int (self.net_info[\"height\"])\n","        \n","                #Get the number of classes\n","                num_classes = int (module[\"classes\"])\n","        \n","                #Transform \n","                x = x.data\n","                x = predict_transform(x, inp_dim, anchors, num_classes, CUDA)\n","                if not write:              #if no collector has been intialised. \n","                    detections = x\n","                    write = 1\n","        \n","                else:       \n","                    detections = torch.cat((detections, x), 1)\n","        \n","            outputs[i] = x\n","        \n","        return detections\n","\n","    def load_weights(self, weightfile):\n","        #Open the weights file\n","        fp = open(weightfile, \"rb\")\n","    \n","        #The first 5 values are header information \n","        # 1. Major version number\n","        # 2. Minor Version Number\n","        # 3. Subversion number \n","        # 4,5. Images seen by the network (during training)\n","        header = np.fromfile(fp, dtype = np.int32, count = 5)\n","        self.header = torch.from_numpy(header)\n","        self.seen = self.header[3]   \n","        \n","        weights = np.fromfile(fp, dtype = np.float32)\n","        \n","        ptr = 0\n","        for i in range(len(self.module_list)):\n","            module_type = self.blocks[i + 1][\"type\"]\n","    \n","            #If module_type is convolutional load weights\n","            #Otherwise ignore.\n","            \n","            if module_type == \"convolutional\":\n","                model = self.module_list[i]\n","                try:\n","                    batch_normalize = int(self.blocks[i+1][\"batch_normalize\"])\n","                except:\n","                    batch_normalize = 0\n","            \n","                conv = model[0]\n","                \n","                \n","                if (batch_normalize):\n","                    bn = model[1]\n","        \n","                    #Get the number of weights of Batch Norm Layer\n","                    num_bn_biases = bn.bias.numel()\n","        \n","                    #Load the weights\n","                    bn_biases = torch.from_numpy(weights[ptr:ptr + num_bn_biases])\n","                    ptr += num_bn_biases\n","        \n","                    bn_weights = torch.from_numpy(weights[ptr: ptr + num_bn_biases])\n","                    ptr  += num_bn_biases\n","        \n","                    bn_running_mean = torch.from_numpy(weights[ptr: ptr + num_bn_biases])\n","                    ptr  += num_bn_biases\n","        \n","                    bn_running_var = torch.from_numpy(weights[ptr: ptr + num_bn_biases])\n","                    ptr  += num_bn_biases\n","        \n","                    #Cast the loaded weights into dims of model weights. \n","                    bn_biases = bn_biases.view_as(bn.bias.data)\n","                    bn_weights = bn_weights.view_as(bn.weight.data)\n","                    bn_running_mean = bn_running_mean.view_as(bn.running_mean)\n","                    bn_running_var = bn_running_var.view_as(bn.running_var)\n","        \n","                    #Copy the data to model\n","                    bn.bias.data.copy_(bn_biases)\n","                    bn.weight.data.copy_(bn_weights)\n","                    bn.running_mean.copy_(bn_running_mean)\n","                    bn.running_var.copy_(bn_running_var)\n","                \n","                else:\n","                    #Number of biases\n","                    num_biases = conv.bias.numel()\n","                \n","                    #Load the weights\n","                    conv_biases = torch.from_numpy(weights[ptr: ptr + num_biases])\n","                    ptr = ptr + num_biases\n","                \n","                    #reshape the loaded weights according to the dims of the model weights\n","                    conv_biases = conv_biases.view_as(conv.bias.data)\n","                \n","                    #Finally copy the data\n","                    conv.bias.data.copy_(conv_biases)\n","                    \n","                #Let us load the weights for the Convolutional layers\n","                num_weights = conv.weight.numel()\n","                \n","                #Do the same as above for weights\n","                conv_weights = torch.from_numpy(weights[ptr:ptr+num_weights])\n","                ptr = ptr + num_weights\n","                \n","                conv_weights = conv_weights.view_as(conv.weight.data)\n","                conv.weight.data.copy_(conv_weights)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wA1wE8ncU1VW","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"8d11da33-0fa0-4e31-e0f4-2e8ec2d46a5f","executionInfo":{"status":"ok","timestamp":1588841545102,"user_tz":-330,"elapsed":721,"user":{"displayName":"Suvramalya Basak","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiruymcmZiCy93QbAK7JUCD4nm8TZqpGuiaizyv=s64","userId":"10962232911980987514"}}},"source":["torch.cuda.is_available()"],"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"tj33OAHGToj0","colab_type":"code","colab":{}},"source":["model = Darknet(\"/content/drive/My Drive/Project/yolov3.cfg\").cuda()\n","inp = get_test_input().cuda()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"i_Jp1tMgUgGM","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":313},"outputId":"e0dc17a2-c856-49dc-bee0-fe4b4f2323a4","executionInfo":{"status":"ok","timestamp":1588841577724,"user_tz":-330,"elapsed":1267,"user":{"displayName":"Suvramalya Basak","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiruymcmZiCy93QbAK7JUCD4nm8TZqpGuiaizyv=s64","userId":"10962232911980987514"}}},"source":["pred = model(inp, torch.cuda.is_available())\n","print (pred)"],"execution_count":19,"outputs":[{"output_type":"stream","text":["tensor([[[1.4531e+01, 1.2696e+01, 1.0480e+02,  ..., 4.1728e-01,\n","          3.6886e-01, 5.0515e-01],\n","         [1.6189e+01, 1.8386e+01, 1.0631e+02,  ..., 4.8104e-01,\n","          5.8089e-01, 5.0841e-01],\n","         [1.6564e+01, 1.4937e+01, 2.8097e+02,  ..., 4.3098e-01,\n","          5.9037e-01, 4.6318e-01],\n","         ...,\n","         [6.0313e+02, 6.0346e+02, 1.0598e+01,  ..., 4.6264e-01,\n","          5.5954e-01, 5.4228e-01],\n","         [6.0385e+02, 6.0438e+02, 9.5360e+00,  ..., 4.6321e-01,\n","          6.0246e-01, 4.7884e-01],\n","         [6.0413e+02, 6.0372e+02, 2.9520e+01,  ..., 3.6353e-01,\n","          5.7741e-01, 4.7458e-01]]], device='cuda:0')\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2973: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n","  \"See the documentation of nn.Upsample for details.\".format(mode))\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"lt7QIcp8Vj4C","colab_type":"code","colab":{}},"source":["model = Darknet(\"/content/drive/My Drive/Project/yolov3.cfg\").cuda()\n","model.load_weights(\"/content/drive/My Drive/Project/yolov3(1).weights\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8lQb06cFz3b7","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"N4ba1C47eaw7","colab_type":"text"},"source":["UTILITIES"]},{"cell_type":"code","metadata":{"id":"5hhJ-hd5ef-9","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}